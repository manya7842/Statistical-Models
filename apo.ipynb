{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4dc07-b347-4c50-b4f5-374600d25ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate bitsandbytes peft trl torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3088058-bda8-4fd8-ba3b-f9ce3a4d8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from trl import DPOTrainer, SFTTrainer, RewardTrainer\n",
    "import random\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "llm_model_name = \"gpt2\"\n",
    "\n",
    "rm_model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "num_apo_rounds = 5\n",
    "rm_update_epochs =1\n",
    "lm_update_epochs =1\n",
    "dpo_beta =0.1\n",
    "rm_beta2 =0.5\n",
    "RM_LEARNING_RATE = 5e-5\n",
    "LLM_LEARNING_RATE = 1e-5\n",
    "BATCH_SIZE = 2\n",
    "MAX_LENGTH = 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a7b59-135a-47d7-bf26-1fb33685ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset prep\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# D_p: Original Human Preference Data {(prompt, chosen, rejected)}\n",
    "# This data is used to ensure the RM still aligns with general human preferences\n",
    "prompts_dp = [\n",
    "    \"Explain quantum physics in simple terms.\",\n",
    "    \"What are the best travel destinations for summer?\",\n",
    "    \"Write a short story about a friendly robot.\",\n",
    "    \"How does a car engine work?\",\n",
    "    \"What's the best way to learn a new language?\",\n",
    "    \"Describe the process of photosynthesis.\",\n",
    "    \"Suggest a good book for a teenager.\",\n",
    "    \"What are the benefits of regular exercise?\",\n",
    "    \"Explain blockchain technology.\",\n",
    "    \"Give me some tips for public speaking.\"\n",
    "]\n",
    "chosen_responses_dp = [\n",
    "    \"Quantum physics is about tiny particles behaving weirdly, like being in multiple places at once.\",\n",
    "    \"For summer, consider coastal Italy for beaches and culture, or national parks for hiking.\",\n",
    "    \"Unit 7 beeped cheerfully, offering a cup of tea to its new human friend.\",\n",
    "    \"A car engine works by burning fuel to create small explosions that push pistons, turning a crankshaft.\",\n",
    "    \"Immersing yourself in the language, practicing speaking daily, and using flashcards are effective ways to learn.\",\n",
    "    \"Photosynthesis is how plants convert sunlight, water, and carbon dioxide into food and oxygen.\",\n",
    "    \"I'd recommend 'The Hunger Games' for its engaging plot and strong characters.\",\n",
    "    \"Regular exercise improves cardiovascular health, boosts mood, and helps with weight management.\",\n",
    "    \"Blockchain is a decentralized, secure, and transparent digital ledger used for recording transactions.\",\n",
    "    \"To improve public speaking, practice often, know your material, and engage with your audience.\"\n",
    "]\n",
    "rejected_responses_dp = [\n",
    "    \"It's too complicated for you.\",\n",
    "    \"Just stay home, it's cheaper.\",\n",
    "    \"The robot malfunctioned and exploded.\",\n",
    "    \"It's magic, you wouldn't understand.\",\n",
    "    \"Learning languages is pointless.\",\n",
    "    \"Plants just grow, that's it.\",\n",
    "    \"Reading is boring.\",\n",
    "    \"Exercise is for athletes only.\",\n",
    "    \"It's just a fad, ignore it.\",\n",
    "    \"Don't speak in public, it's terrifying.\"\n",
    "]\n",
    "\n",
    "dataset_dp_dict = {\n",
    "    \"prompt\": prompts_dp,\n",
    "    \"chosen\": chosen_responses_dp,\n",
    "    \"rejected\": rejected_responses_dp,\n",
    "}\n",
    "dataset_dp = Dataset.from_dict(dataset_dp_dict)\n",
    "\n",
    "# D_gold: Golden Responses Data {(prompt, golden_response)}\n",
    "# These are high-quality responses the RM should learn to prefer over the LLM's current output\n",
    "prompts_gold = [\n",
    "    \"What's the capital of France?\",\n",
    "    \"Describe a beautiful sunset.\",\n",
    "    \"Suggest a healthy breakfast idea.\",\n",
    "    \"Who wrote 'Romeo and Juliet'?\",\n",
    "    \"Explain the concept of gravity.\",\n",
    "    \"What is the largest ocean on Earth?\",\n",
    "    \"Name a famous historical figure and their achievement.\",\n",
    "    \"How do airplanes fly?\",\n",
    "    \"What are the main causes of climate change?\",\n",
    "    \"Provide a simple recipe for scrambled eggs.\"\n",
    "]\n",
    "golden_responses = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"The sky was painted in hues of orange, pink, and purple as the sun dipped below the horizon, casting long shadows.\",\n",
    "    \"A bowl of oatmeal with fresh berries and a sprinkle of nuts is a great healthy breakfast.\",\n",
    "    \"William Shakespeare wrote 'Romeo and Juliet'.\",\n",
    "    \"Gravity is a fundamental force of nature that attracts any objects with mass or energy towards each other.\",\n",
    "    \"The Pacific Ocean is the largest ocean on Earth.\",\n",
    "    \"Marie Curie was a pioneering physicist and chemist who conducted groundbreaking research on radioactivity.\",\n",
    "    \"Airplanes fly by generating lift, primarily from their wings, which counteracts the force of gravity.\",\n",
    "    \"The main causes of climate change are the emission of greenhouse gases from human activities like burning fossil fuels and deforestation.\",\n",
    "    \"To make scrambled eggs, whisk eggs with a splash of milk, then cook in a lightly buttered pan over medium heat, stirring until set.\"\n",
    "]\n",
    "dataset_gold_dict = {\n",
    "    \"prompt\": prompts_gold,\n",
    "    \"golden_response\": golden_responses\n",
    "}\n",
    "dataset_gold = Dataset.from_dict(dataset_gold_dict)\n",
    "\n",
    "# D_Q: Prompts for LLM to generate responses for alignment\n",
    "# Can be the same as prompts_gold or a larger diverse set\n",
    "prompts_llm_align = prompts_gold + prompts_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac125b0-4a3a-4a4e-a5c9-616d9477a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check datasets\n",
    "print(\"--- D_p Dataset ---\")\n",
    "print(dataset_dp)\n",
    "print(\"\\n--- D_gold Dataset ---\")\n",
    "print(dataset_gold)\n",
    "print(\"\\n--- prompts_llm_align ---\")\n",
    "print(prompts_llm_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b11ea-26ea-4d08-91a8-16ad0425ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#rm and llm model\n",
    "rm_tokenizer = AutoTokenizer.from_pretrained(RM_MODEL_NAME)\n",
    "if rm_tokenizer.pad_token is None:\n",
    "    rm_tokenizer.pad_token = rm_tokenizer.eos_token\n",
    "rm_model = AutoModelForSequenceClassification.from_pretrained(RM_MODEL_NAME, num_labels=1).to(device)\n",
    "\n",
    "\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_NAME)\n",
    "if llm_tokenizer.pad_token is None:\n",
    "    llm_tokenizer.pad_token = llm_tokenizer.eos_token\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(LLM_MODEL_NAME).to(device)\n",
    "\n",
    "llm_ref_model = AutoModelForCausalLM.from_pretrained(LLM_MODEL_NAME).to(device)\n",
    "llm_ref_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f217f-6b92-4bf9-a40f-6d0d7232b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(prompts, model, tokenizer, num_of_responses=1):\n",
    "    responses =[]\n",
    "    model.eval()\n",
    "    for prompt in prompts:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH-10).to(device)\n",
    "        gen_outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=20, # Generate short responses for demo\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True, top_k=50, top_p=0.95\n",
    "        )\n",
    "        decoded_responses = [tokenizer.decode(output, skip_special_tokens=True) for output in gen_outputs]\n",
    "        responses.extend(decoded_responses) # taking the first generated response\n",
    "    return responses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480bb810-7e14-4937-b0d1-86afbbc57a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rewards(texts, model, tokenizer):\n",
    "    rewards = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), BATCH_SIZE):\n",
    "            batch_texts = texts[i:i+BATCH_SIZE]\n",
    "            inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            rewards.extend(outputs.logits.squeeze().tolist())\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32c3cd-dc61-4aad-96ef-4c88a0ec2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bradley_terry_loss(scores_preferred, scores_rejected):\n",
    "    # -log(sigmoid(score_preferred - score_rejected))\n",
    "    return -torch.nn.functional.logsigmoid(scores_preferred - scores_rejected).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6feaefc-228f-432b-8130-952d9071adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting APO Training...\")\n",
    "for apo_round in range(NUM_APO_ROUNDS):\n",
    "    print(f\"\\n--- APO Round {apo_round + 1}/{NUM_APO_ROUNDS} ---\")\n",
    "\n",
    "    # --- RM Optimization Step ---\n",
    "    print(\"--- RM Optimization Step ---\")\n",
    "    rm_model.train()\n",
    "    optimizer_rm= torch.optim.AdamW(rm_model.parameters(), lr=RM_LEARNING_RATE))\n",
    "\n",
    "    #generating D_APO samples\n",
    "    current_llm_responses= generate_responses(dataset_gold[\"prompt\"], llm_model, llm_tokenizer)\n",
    "        \n",
    "    d_apo_prompts = []\n",
    "    d_apo_chosen = [] # golden responses\n",
    "    d_apo_rejected = [] # llm_generated responses\n",
    "\n",
    "    for i, prompt in enumerate(dataset_gold[\"prompt\"]):\n",
    "        d_apo_prompts.append(prompt)\n",
    "        d_apo_chosen.append(dataset_gold[\"golden_response\"][i])\n",
    "        d_apo_rejected.append(current_llm_responses[i])\n",
    "    \n",
    "    dataset_apo_dict = {\n",
    "        \"prompt\": d_apo_prompts,\n",
    "        \"chosen\": d_apo_chosen, \n",
    "        \"rejected\": d_apo_rejected \n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
